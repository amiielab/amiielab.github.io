<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>Research | AMIIE Research and Educational Laboratory</title>
  <meta content="AMIIE Research and Educational Laboratory | Applied Machine Intelligence Initiatives &amp; Education Lab (AMIIE Lab)" name="description">
  <meta content="AMIIE Research and Educational Laboratory (AMIIE Lab)" name="keywords">


  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/main.css" rel="stylesheet">

</head>

<body class="portfolio-details-page">

  <header id="header" class="header d-flex align-items-center fixed-top">
    <div class="container-fluid container-xl position-relative d-flex align-items-center justify-content-between">
    <div class="top-link-nav"><a href="https://www.pace.edu/" target="_blank">Pace University</a></div>
      <a href="index.html" class="logo d-flex align-items-center">
        <img src="assets/img/logo.png" alt="AMIIE Research and Educational Laboratory" class="logo">
      </a>

      <nav id="navmenu" class="navmenu pt-4">
        <ul>
          <li><a href="index.html" >Home</a></li>
          <li><a href="people.html" >People</a></li>
          <li><a href="research.html" class="active">Research</a></li>
          <li><a href="education.html">Education</a></li>
          <li><a href="publications.html">Publications</a></li>
          <li><a href="openings.html">Openings</a></li>
          <li><a href="github-repo.html">GitHub Repo</a></li>
          <li><a href="webinar-series.html">Webinar Series</a></li>
        </ul>
        <i class="mobile-nav-toggle d-xl-none bi bi-list"></i>
      </nav>

    </div>
  </header>

  <main class="main">

    <!-- Page Title -->
    <div class="page-title dark-background" data-aos="fade" style="background-image: url(assets/img/AMIIE-carousel-3.jpg);">
      <div class="container position-relative">
        <h1>Research</h1>
      </div>
    </div><!-- End Page Title -->


    <section id="about" class="about section">

      <div class="container">

        <div class="row gy-4">

          <div class="col-lg-12 content justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>Semi-supervised Pipeline for Medical Image Segmentation</h3>
            <p class="text-justify">
             In recent years, medical imaging has witnessed significant advances through the application of deep learning methods. However, several fundamental challenges are hindering their full potential in clinical settings. Notably, deep learning models often require large amounts of training data to achieve high accuracy, making their implementation expensive or even impossible in healthcare scenarios. Fortunately collecting unlabeled images is feasible in many tasks. To overcome the challenge of resource-intensive annotation, researchers have turned to semi-supervised learning methods, which enable researchers to utilize labeled and unlabeled images by combining supervised and unsupervised learning. Our work aims to utilize the semi-supervised learning to tackle the problem of knee joint space segmentation in plain radiographs, using only a few manually segmented radiographs.
            </p>
            <center><img src="assets/img/research_06.jpg" class="img-fluid" alt="AMIIE Research and Educational Laboratory" style="max-width:600px"></center>
          </div>

        </div>

      </div>
    </section>
    <section id="about" class="about section light-background">

      <div class="container">

        <div class="row gy-4">

          <div class="col-lg-12 content justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>Unbiased Image Segmentation using Plain Knee Radiographs</h3>
            <p class="text-justify">
             Automatic segmentation of knee bony anatomy is essential in orthopedics, and it has been around for several years in both pre-operative and post-operative settings. While deep learning algorithms have demonstrated exceptional performance in medical image analysis, the assessment of fairness and potential biases within these models remains limited. This study aims to revisit deep learning-powered knee-bony anatomy segmentation using plain radiographs to uncover visible gender and racial biases. The current contribution offers the potential to advance our understanding of biases, and it provides practical insights for researchers and practitioners in medical imaging. The proposed mitigation strategies mitigate gender and racial biases, ensuring fair and unbiased segmentation results. Furthermore, this work promotes equal access to accurate diagnoses and treatment outcomes for diverse patient populations, fostering equitable and inclusive healthcare provision.
</p>
            <center><img src="assets/img/research_05.jpg" class="img-fluid" alt="AMIIE Research and Educational Laboratory" style="max-width:600px"></center>
          </div>

        </div>

      </div>
    </section>
    <section id="about" class="about section">

      <div class="container">

        <div class="row gy-4">

          <div class="col-lg-12 content justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>Textual Dataset(s) to Advance Open Scientific Research in Total Joint Arthroplasty</h3>
            <p class="text-justify">
            otal joint arthroplasty (TJA) is the most common and fastest inpatient surgical procedure in the elderly, nationwide. With the growing number of TJA patients and advances being made in healthcare settings, an increasing number of scientific articles are now published in a daily basis, representing invaluable information in TJA, ranging from TJA diagnosis, prevention, and treatment strategies to genetic variants and epidemiological factors. However, little is done to computationally assemble a large-scale textual dataset from scientific articles, and make it publicly available for open scientific research in TJA. Rapid yet computational text analytics on such a large-scale scientific literature has a great potential to discover novel knowledge in better understanding joint diseases, improving the quality of care and clinical outcomes for TJA.
</p>
            <center><img src="assets/img/research_04.jpg" class="img-fluid" alt="AMIIE Research and Educational Laboratory" style="max-width:600px"></center>
          </div>

        </div>

      </div>
    </section>
    <section id="about" class="about section light-background">

      <div class="container">

        <div class="row gy-4">

          <div class="col-lg-12 content justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>Al Fairness in Hip Bony Anatomy Segmentation</h3>
            <p class="text-justify">
             Automatic segmentation of hip bony anatomy is a critical component of orthopedics enabling healthcare providers and clinicians to efficiently and objectively accomplish several medical image analysis tasks, including the diagnosis of hip fractures, arthritis, deformity, and dislocation. This autonomous process assists surgeons in preoperative planning by determining the location and size of surgical incisions, the placement of hip implants, and/or other surgical instruments. While deep learning computer vision algorithms for hip segmentation have demonstrated almost human-like performance in past literature, analyzing the fairness and any potential bias within such models has been very limited so far. Thus, the present work aims to provide a better understanding of any visible gender, ethnicity, and racial bias in hip bony anatomy segmentation using plain radiographs.
</p>
            <center><img src="assets/img/research_03.jpg" class="img-fluid" alt="AMIIE Research and Educational Laboratory" style="max-width:600px"></center>
          </div>

        </div>

      </div>
    </section>
    <section id="about" class="about section">

      <div class="container">

        <div class="row gy-4">

          <div class="col-lg-12 content justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>Word Embedding Neural Networks to Advance Knee Osteoarthritis Research</h3>
            <p class="text-justify">
            Osteoarthritis (OA) is the most prevalent chronic joint disease worldwide, where knee OA takes more than 80% of commonly affected joints. Although knee OA carries a list of well-known terminology aiming to standardize the nomenclature of the diagnosis, prognosis, treatment, and clinical outcomes of the chronic joint disease, in practice there is a wide range of terminology associated with knee OA across different data sources, including but not limited to biomedical literature, clinical notes, healthcare literacy, and health-related social media. Rapid yet, accurate text mining on large-scale scientific literature may discover novel knowledge and terminology to better understand knee OA and to improve the quality of knee OA diagnosis, prevention, and treatment. The present works aim to utilize artificial neural network strategies to automatically extract vocabularies associated with knee OA diseases. Our finding indicates the feasibility of developing word embedding neural networks for autonomous keyword extraction and abstraction of knee OA.
</p>
            <center><img src="assets/img/research_02.jpg" class="img-fluid" alt="AMIIE Research and Educational Laboratory" style="max-width:600px"></center>
          </div>

        </div>

      </div>
    </section>
    <section id="about" class="about section light-background">

      <div class="container">

        <div class="row gy-4">

          <div class="col-lg-12 content justify-content-center" data-aos="fade-up" data-aos-delay="100">
            <h3>Explainable Deep Few-Shot Learning in Knee Radiography Analysis</h3>
            <p class="text-justify">
             Rapid yet, deep learning medical image analysis has already shown success in a variety of knee image analysis tasks, ranging from knee joint area localization to joint space segmentation and measurement, with almost a human-like performance. However, there are several fundamental challenges that stop deep learning methods to obtain their full potential in a clinical setting such as orthopedics. These include the need for a large number of gold- standard, manually annotated training images and a lack of explainability and interpretability. To address these challenges, this study is the first to present an explainable deep few-shot learning model that can localize the knee joint area and segment the joint space in plain knee radiographs, using only a small number of manually annotated radiographs.</p>
            <center><img src="assets/img/research_01.jpg" class="img-fluid" alt="AMIIE Research and Educational Laboratory" style="max-width:600px"></center>
          </div>

        </div>

      </div>
    </section>
   
	

  </main>

  <footer id="footer" class="footer dark-background">

    <div class="footer-top">
      <div class="container">
        <div class="row">

          <div class="col-lg-4 col-md-2 footer-links">
            <img src="assets/img/thumbnail-logo-w.png" class="img-fluid" alt="Applied AI Research and Education to Solve Real-World Problems" style="width: 100%;max-width: 200px;">
          </div>


          <div class="col-lg-4 col-md-4 footer-contact">
            <h4>Location</h4>
            <p>
<a href="https://www.pace.edu/" target="_blank">Pace University</a><br>
Seidenberg School of CSIS<br>
One Pace Plaza<br>
New York, NY 10038 <br>
            </p>

          </div>

          <div class="col-lg-4 col-md-6 footer-info">
            <h4>Contact</h4>
            <p>
			<strong>Email:</strong> samirian@pace.edu<br>
            <strong>Phone:</strong> (+1) 800-874-PACE <br>
			</p>
            
          </div>

        </div>
      </div>
    </div>

    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>Applied Machine Intelligence Initiatives & Education Lab (AMIIE Lab)</span></strong>. All Rights Reserved
      </div>
    </div>



  </footer>

  <!-- Scroll Top -->
  <a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Preloader -->
  <div id="preloader"></div>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/imagesloaded/imagesloaded.pkgd.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>